{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad1d618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Waleed Akram \n",
    "## 20P-0640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b09641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import os.path\n",
    "\n",
    "# Loading the Urdu language model for spaCy\n",
    "nlp = spacy.blank(\"ur\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3a6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        corpus = file.readlines()\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74956fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus):\n",
    "    # Striping whitespaces and adding \" \" at the start and end of each line\n",
    "    return ['\"{}\"'.format(line.strip()) for line in corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93fa4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unigram_model(corpus):\n",
    "    unigram_model = {}\n",
    "    for doc in corpus:\n",
    "        for token in doc:\n",
    "            unigram_model[token.text] = unigram_model.get(token.text, 0) + 1\n",
    "    return unigram_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fcee284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigram_model(corpus):\n",
    "    bigram_model = {}\n",
    "    for doc in corpus:\n",
    "        for i in range(len(doc) - 1):\n",
    "            current_token = doc[i].text\n",
    "            next_token = doc[i + 1].text\n",
    "            if current_token in bigram_model:\n",
    "                bigram_model[current_token].append(next_token)\n",
    "            else:\n",
    "                bigram_model[current_token] = [next_token]\n",
    "    return bigram_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219fbf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_verse_unigram(unigram_model):\n",
    "    verse_length = random.randint(7, 10)\n",
    "    verse = []\n",
    "    for _ in range(verse_length):\n",
    "        verse.append(random.choice(list(unigram_model.keys())))\n",
    "    return ' '.join(verse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d562b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_verse_bigram(bigram_model, starting_word):\n",
    "    verse_length = random.randint(7, 10)\n",
    "    verse = [starting_word]\n",
    "    for _ in range(verse_length - 1):\n",
    "        if verse[-1] in bigram_model:\n",
    "            next_word = random.choice(bigram_model[verse[-1]])\n",
    "            verse.append(next_word)\n",
    "        else:\n",
    "            break\n",
    "    return ' '.join(verse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76d97513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the filename you want to read (e.g., 'corpus.txt', 'iqbal.txt', 'faiz.txt', 'ghalib.txt'): sample_corpus.txt\n",
      "سب ہے لوٹیں شاخ مجھے کچھ آ\n",
      "رہتی میں دن مایوسیوں کو زندہ پیاس ہی بہار دل\n",
      "جاؤ لوٹیں کر خود ہوں مایوسیوں ، محبت تو\n",
      "\n",
      "کہ زندہ ہوں میں ابھی ، \" \"\n",
      "میں ابھی \" , \" , \" , \"\n",
      "\" مایوسیوں کی قید سے نکال کر\n",
      "\n",
      "---\n",
      "\n",
      "سیراب جاؤ کر ابھی ہیں خلوص کے کہ مرتی\n",
      "کر , نکال دن لوٹیں دل , ہے\n",
      "تو تو ہی سچ ، وفا پھر\n",
      "\n",
      ", \" , \" آ جاؤ میرے پاس کہ زندہ\n",
      "نکال کر کبھی تو دید سے نکال کر کبھی تو\n",
      "کہ زندہ ہوں میں آس کہ زندہ ہوں میں ابھی\n",
      "\n",
      "---\n",
      "\n",
      "وفا شاخ چشم آ شاخ گے رہتی , دید ہیں\n",
      "یاس تو خلوص ہوتا کیوں کی اداس کیوں آس ,\n",
      "کچھ سب پیاس خلوص آ زندہ دن\n",
      "\n",
      "دل سے خود کو نکال یاس کہ زندہ\n",
      "\" لوٹیں گے تیرے آتے ہی پھر دن بہار کے\n",
      "سے سیراب کر کبھی تو دید سے\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ask user for the filename\n",
    "while True:\n",
    "    filename = input(\"Enter the filename you want to read (e.g., 'sample_corpus.txt', 'iqbal.txt', 'faiz.txt', 'ghalib.txt'): \")\n",
    "    if os.path.isfile(filename):\n",
    "        corpus = read_corpus(filename)\n",
    "        tokenized_corpus = [nlp(text) for text in tokenize_corpus(corpus)]\n",
    "\n",
    "        unigram_model = generate_unigram_model(tokenized_corpus)\n",
    "        bigram_model = generate_bigram_model(tokenized_corpus)\n",
    "\n",
    "        break\n",
    "    else:\n",
    "        print(\"File does not exist. Please enter a valid filename.\")\n",
    "\n",
    "# Generate three stanzas\n",
    "for _ in range(3):\n",
    "    # Generating first verse\n",
    "    starting_word = random.choice(list(tokenized_corpus[0]))\n",
    "    verse1_unigram = generate_verse_unigram(unigram_model)\n",
    "    verse1_bigram = generate_verse_bigram(bigram_model, starting_word.text)\n",
    "\n",
    "    # Generating second verse\n",
    "    starting_word = random.choice(list(tokenized_corpus[0]))\n",
    "    verse2_unigram = generate_verse_unigram(unigram_model)\n",
    "    verse2_bigram = generate_verse_bigram(bigram_model, starting_word.text)\n",
    "\n",
    "    # Generating third verse\n",
    "    starting_word = random.choice(list(tokenized_corpus[0]))\n",
    "    verse3_unigram = generate_verse_unigram(unigram_model)\n",
    "    verse3_bigram = generate_verse_bigram(bigram_model, starting_word.text)\n",
    "\n",
    "    # Printing the stanza\n",
    "    print(verse1_unigram)\n",
    "    print(verse2_unigram)\n",
    "    print(verse3_unigram)\n",
    "    print()\n",
    "    print(verse1_bigram)\n",
    "    print(verse2_bigram)\n",
    "    print(verse3_bigram)\n",
    "    print(\"\\n---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def13f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
